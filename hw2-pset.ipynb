{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a037482-6f27-4512-8d73-988ffb0d50b6",
   "metadata": {},
   "source": [
    "# HW 2: Candidates vs. Presidents\n",
    "\n",
    "**Content Warning:** This assignment discusses United States politics.\n",
    "\n",
    "In this homework assignment, you will study the statistical characteristics of speeches made by United States presidents and presidential candidates. In HW 1, you implemented code for conducting keyword analysis on a tokenized corpus; you will have an opportunity to use your code from HW 1 for this assignment. In this assignment, you will expand upon HW 1 by implementing the following functionalities:\n",
    "- extracting text from webpages\n",
    "- repairing NLTK corpora with encoding errors\n",
    "- conducting _key feature analysis_ [(Egbert and Biber, 2023)](https://www.euppublishing.com/doi/10.3366/cor.2023.0275), where keyness is measured for high-level syntacticâ€“pragmatic features instead of just token types\n",
    "- comparing sets of corpora with one another, instead of just comparing a single target corpus to a single reference corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0cd939f2d7e64",
   "metadata": {},
   "source": [
    "## Problem 0: Background (No Submission, 0 Points)\n",
    "\n",
    "In this problem, you will learn relevent background information about the United States presidency.\n",
    "\n",
    "This problem was written primarily for the benefit of international students and/or students not familiar with US politics. If you are familiar with US presidential inaugurations and nominating conventions, you may skip this problem.\n",
    "\n",
    "### Problem 0a: Understand US Presidential Elections (No Submission, 0 Points)\n",
    "\n",
    "The United States president is chosen every four years via a _presidential election_. Most US citizens can participate in presidential elections by _voting_ in one of the 50 states or the District of Columbia. Exceptions include citizens under 18 years of age, citizens convicted of certain crimes, citizens not registered to vote, and citizens residing in [US territories](https://en.wikipedia.org/wiki/Territories_of_the_United_States).\n",
    "\n",
    "Most US politicians, as well as many US voters, belong to one of two _political parties_: the [Democratic Party](https://democrats.org/) and the [Republican Party](https://www.gop.com/). The current president, Donald Trump, belongs to the Republican Party, while the previous president, Joe Biden, belongs to the Democratic Party. Presidential candidates may also represent smaller parties (like the [Libertarian Party](https://lp.org/) or the [Green Party](https://www.gp.org/)) or run without a party affiliation, but such candidates are usually unsuccessful. The most recent president who belonged to neither the Democratic nor the Republican Party was [Millard Fillmore](https://en.wikipedia.org/wiki/Millard_Fillmore) from the [Whig Party](https://en.wikipedia.org/wiki/Whig_Party_(United_States)), who served from 1850 to 1853.\n",
    "\n",
    "Before each presidential election, each party wishing to participate in the election holds a _nominating convention_ where the official candidate for that party is chosen. The nominating conventions for the most recent presidential election (2024) are shown below.\n",
    "\n",
    "|   |   | Location | Dates | Presidential Nominee | \n",
    "|---|---|---|---|---|\n",
    "| Democratic National Convention | (DNC) | Chicago, IL | Aug. 19â€“22 | Kamala Harris | \n",
    "| Republican National Convention | (RNC) | Milwaukee, WI | Jul. 15â€“18 | Donald Trump | \n",
    "| Libertarian National Convention | (LNC) | Washington, DC | May 24â€“27 | Chase Oliver | \n",
    "| Green National Convention | (GNC) | Online | Aug. 15â€“18 | Jill Stein | \n",
    "\n",
    "After each presidential election, the winner of the election officially becomes president during the _inauguration ceremony_, held in January the following year.\n",
    "\n",
    "### Problem 0b: Understand US Presidential Speeches (No Submission, 0 Points)\n",
    "\n",
    "In this assignment, we will be studying two kinds of speeches:\n",
    "- _nomination acceptance speeches_ given at a party convention, where a new presidential candidate explains why they should be president\n",
    "- _inaugural addresses_ given at an inauguration ceremony, where a new president explains their goals for the next four years.\n",
    "\n",
    "Here is an example of each kind of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaddf345-c5e0-4847-9e6d-4d355f48a91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Candidate Kamala Harris's 2024 Nomination Acceptance Speech</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/9hy2cZaGbOM?si=v8_rHO7-AyVXXsam\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7cd1503b4d70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>President Donald Trump's 2025 Inaugural Address</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/WQuk73KIqZ8?si=W_QYPMZtV3PHuuNG\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7cd1505c6350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for embedding YouTube videos in a Jupyter Notebook\n",
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "display(HTML(\"<h4>Candidate Kamala Harris's 2024 Nomination Acceptance Speech</h4>\"))\n",
    "display(IFrame(\"https://www.youtube.com/embed/9hy2cZaGbOM?si=v8_rHO7-AyVXXsam\", width=560, height=315))\n",
    "\n",
    "display(HTML(\"<h4>President Donald Trump's 2025 Inaugural Address</h4>\"))\n",
    "display(IFrame(\"https://www.youtube.com/embed/WQuk73KIqZ8?si=W_QYPMZtV3PHuuNG\", width=560, height=315))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f4be7-a8c8-4e83-b0b5-75c003bdd4b6",
   "metadata": {},
   "source": [
    "## Problem 1: Programming Exercises (5 Points in Total + 1 Point Extra Credit)\n",
    "\n",
    "In these exercises, you will learn and practice computer programming concepts needed for Problems 2 and 3.\n",
    "\n",
    "**Note:** In many parts of Problems 2 and 3, you will benefit from referring back to this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d71df9-607f-4ec3-8e4e-4f10ed7d9524",
   "metadata": {},
   "source": [
    "### Problem 1a: Understand UTF-8 Morphosyntax (Written, 1 Point)\n",
    "\n",
    "Recall that UTF-8 encodes characters using **1 to 4 bytes**â€”that is, each character is represented as a sequence of 8, 16, 24, or 32 **bits** (1s and 0s).\n",
    "\n",
    "Please look at the following characters and their binary encodings in UTF-8.\n",
    "\n",
    "|   | UTF-8 Binary |   | UTF-8 Binary |\n",
    "|---|--------------|---|--------------|\n",
    "| `\\n` | **0**0001010 | `à¨Š`  | **1110**0000 **10**101000 **10**001010  |\n",
    "| `8`  | **0**0111000 | `áŠ` | **1110**0001 **10**001111 **10**001010  |\n",
    "| `L`  | **0**1001100 | `å—¨` | **1110**0101 **10**010111 **10**101000 |\n",
    "| `x`  | **0**1111000 | `ì§·` | **1110**1100 **10**100111 **10**110111 |\n",
    "| `Â¥` | **110**00010 **10**100101 | `ð’€‚` | **11110**000 **10**010010 **10**000000 **10**000010 |\n",
    "| `Å™` | **110**00101 **10**011001 | `ð“…ˆ` | **11110**000 **10**010011 **10**000101 **10**001000 |\n",
    "| `Î¨` | **110**01110 **10**101000 | `ð„ž` | **11110**000 **10**011101 **10**000100 **10**011110 |\n",
    "| `Ô¹` | **110**10100 **10**111001 | `ðŸ˜…` | **11110**000 **10**011111 **10**011000 **10**000101 |\n",
    "\n",
    "Notice that the bytes (sequences of 8 bits) in these encodings seem to have a systematic \"morphology.\" What do the prefixes 0-, 10-, 110-, 1110-, and 11110- mean? \n",
    "\n",
    "**Hint:** The prefixes are highlighted in bold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2ce63-8e74-4a32-85ea-d3e2fd20a1e5",
   "metadata": {},
   "source": [
    "### Problem 1b: Explain UTF-8 Morphosyntax (Written, 1 Point Extra Credit)\n",
    "\n",
    "Why do you think UTF-8 has this \"morphosyntax\"?\n",
    "\n",
    "**Hint:** Look at the following UTF-8 binary code:\n",
    "```\n",
    "01011001 11000011 10111010 01101100 11000011 10111001\n",
    "```\n",
    "Without looking it up, can you tell how many characters are in the above byte sequence? Can you tell where the character boundaries are?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0483ff-4479-4a69-b770-0c96ffd66d3b",
   "metadata": {},
   "source": [
    "### Problem 1c: Understand Python Errors (No Submission, 0 Points)\n",
    "\n",
    "In class, we have seen many instances where problematic Python code can result in an error. There are two kinds of errors in Python: _syntax errors_ and _runtime errors_. Runtime errors are also known as _exceptions_.\n",
    "\n",
    "Syntax errors occur when you try to run Python code that is \"ungrammatical\"; i.e., its syntax does not comply with the Python grammar. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee52538-2f88-47eb-86fa-3cc978104679",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (918557178.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31m1 +\u001B[39m\n       ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Code that triggers a syntax error\n",
    "1 +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d3317-8b25-4935-8f35-55f84bef5fd2",
   "metadata": {},
   "source": [
    "Runtime errors occur when you try to run Python code that is \"semantically infelicitous.\" Such code is syntactically valid (and therefore you can run it), but while running the code, you end up trying to perform a computation that is meaningless or logically incoherent. For example, the following code triggers a `ZeroDivisonError`, which is a subclass of `RuntimeError`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ee5225-f8a5-46d9-b002-8ada6a3a3580",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mZeroDivisionError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Code that triggers a runtime error\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[32;43m5\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m/\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\n",
      "\u001B[31mZeroDivisionError\u001B[39m: division by zero"
     ]
    }
   ],
   "source": [
    "# Code that triggers a runtime error\n",
    "5 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7148b2e-fa4d-4190-90bf-072724643d7a",
   "metadata": {},
   "source": [
    "When writing Python code, you can manually trigger a runtime error by using the `raise` keyword, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c00cea-073c-41c2-b938-182e3c6b72f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: "
     ]
    }
   ],
   "source": [
    "raise RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eacf5b-cd22-4f44-a292-aba6c71ff4dd",
   "metadata": {},
   "source": [
    "Some \"real-life\" examples of errors occur in the `.py` files provided with this assignment. Each of the functions you are supposed to implement starts out with the following code:\n",
    "```python\n",
    "raise NotImplementedError(\"Please replace this line with your code.\")\n",
    "```\n",
    "If you try to run one of these functions from this notebook, you will get a runtime error, more specifically a `NotImplementedError`. If someone else were using your code to perform keyword analysis, the `NotImplementedError` would tell them that some of your functions are not working because you have not implemented them yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d44b106-a9b7-448f-83fb-36f86eb3d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to [path redacted]...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "This function has no implementation.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Code that triggers a NotImplementedError\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mhw2\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mhw2\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfunction_without_implementation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m[path redacted]/hw2.py:15\u001B[39m, in \u001B[36mfunction_without_implementation\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfunction_without_implementation\u001B[39m():\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mThis function has no implementation.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNotImplementedError\u001B[39m: This function has no implementation."
     ]
    }
   ],
   "source": [
    "# Code that triggers a NotImplementedError\n",
    "import hw2\n",
    "\n",
    "hw2.function_without_implementation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3198a48-ac1b-4bfa-82aa-5640dfb6c74d",
   "metadata": {},
   "source": [
    "### Problem 1d: Understand Exception Handling (Written, 1 Point)\n",
    "\n",
    "A very useful Python construct for dealing with runtime errors is the _`try`â€”`except`_ block. This construct does something called _exception handling_. Here's an example of how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3471c1-b919-4c6f-b261-1b3fa47626e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tried to divide by zero!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(5 / 0)\n",
    "except ZeroDivisionError:\n",
    "    print(\"I tried to divide by zero!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054bea7e-9b2d-472e-9f4e-e160e2ff9cdb",
   "metadata": {},
   "source": [
    "And here's a somewhat more \"realistic\" example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "975b3549-a739-4524-85a7-30d0e53e28f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/-5 = -0.2\n",
      "1/-4 = -0.25\n",
      "1/-3 = -0.3333333333333333\n",
      "1/-2 = -0.5\n",
      "1/-1 = -1.0\n",
      "1/1 = 1.0\n",
      "1/2 = 0.5\n",
      "1/3 = 0.3333333333333333\n",
      "1/4 = 0.25\n"
     ]
    }
   ],
   "source": [
    "for i in range(-5, 5):\n",
    "    try:\n",
    "        print(f\"1/{i} = {1 / i}\")\n",
    "    except ZeroDivisionError:\n",
    "        pass  # \"pass\" means \"do nothing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2174d-a995-4ebf-b796-16d95cb756f2",
   "metadata": {},
   "source": [
    "What does the `try`â€”`except` block do? When does the code under the `try` block run, and when does the code under the `except` block run?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08634fa-d0f5-4d64-8e85-5712f6cd7dc5",
   "metadata": {},
   "source": [
    "### Problem 1e: Understand Loop Breaking (Written, 1 Point)\n",
    "\n",
    "Please look at the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6012d4ac-d38d-4c59-99f5-d3ae18e0fc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a, b, c, d, e'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join([\"a\", \"b\", \"c\", \"d\", \"e\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5fd084-4c84-47ef-8bb1-cfdb240b5670",
   "metadata": {},
   "source": [
    "Let's say `a` is a `str`, and `b` is a `list[str]`. What does `a.join(b)` do? Does it still work if `b` is a `set`? What if `b = range(10)`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048ab73-7a4d-4c06-901d-267a432117fa",
   "metadata": {},
   "source": [
    "### Problem 1f: Understand Loop Breaking (Written, 1 Point)\n",
    "\n",
    "Please look at the following code snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc7529f-c8a3-4141-84f0-31de34e7aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    print(i)\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ca7010-4615-4510-8697-8eb19eb2ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 100):\n",
    "    if i % 3 == 0 and i % 5 == 0:  \n",
    "        # i is divisible by 3 and 5\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94a0c9-f78b-402b-8d57-501e43a048f1",
   "metadata": {},
   "source": [
    "What does `break` do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b933eec-9b4a-48d6-9ead-02f553ff5497",
   "metadata": {},
   "source": [
    "### Problem 1g: Understand the NLTK Tokenizer (Written, 1 Point)\n",
    "\n",
    "NLTK has a function called `word_tokenize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665fc063-bfcb-4f82-9518-015c11d182fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.word_tokenize(\"The quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eac7a9-b6cb-486b-b8fc-ae2598b8c22a",
   "metadata": {},
   "source": [
    "What does this function do? (In your answer, do not use the word \"tokenize,\" except in the name of the `word_tokenize` function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f08c9a-49b0-4c43-9187-33740a3f6d62",
   "metadata": {},
   "source": [
    "## Problem 2: Analysis of Inaugural Addresses (7 Points in Total)\n",
    "\n",
    "In this problem, you will use the code from HW 1, provided with this assignment, to conduct keyword analysis of US inaugural addresses. You will conduct the analysis using the Inaugural Addresses corpus from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a46257-58c0-4879-9234-ce53b98c1e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to [path redacted]...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the Inaugural Addresses corpus if you haven't already\n",
    "nltk.download(\"inaugural\")\n",
    "\n",
    "# Load the Inaugural Addresses corpus\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd668de7-13f1-4ebb-9f35-ebdebd3f81a0",
   "metadata": {},
   "source": [
    "The HW 1 code provided with this assignment is slightly different from the HW 1 solution. **Please make sure you use the `hw1.py` file provided with this assignment, and not a different `hw1.py` file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e2fdad-d45f-4ae1-ae68-865d6d2f2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load other code that we will use in this problem\n",
    "from nltk.probability import FreqDist\n",
    "import hw1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1c33b-44cf-4f20-be01-33224a54e546",
   "metadata": {},
   "source": [
    "### Problem 2a: Attempt to Analyze an Inaugural Address (Written, 1 Point)\n",
    "\n",
    "Using the entire Inaugural Addresses corpus as a reference, and using a smoothing constant of $k = 1$, what are the top five keywords of Donald Trump's 2025 inaugural address?\n",
    "\n",
    "**Hint:** Use the code from HW 1, and consult [Chapter 2, Section 1](https://www.nltk.org/book/ch02.html#corpora_index_term) of the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071ec9c-b084-4a73-8cde-c77f4807f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code to help you solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cd612-9678-417a-9d32-3aef7abcc6e5",
   "metadata": {},
   "source": [
    "### Problem 2b: Understand Encoding Issues (Written, 1 Point)\n",
    "\n",
    "One of the keywords for Donald Trump's 2025 inauguration speech is `'\\x80\\x99'`. Let's look at the places in this speech where this token shows up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e210b0-152c-4438-850a-a767162e841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "thout even a token of defense . TheyÃ¢ Â€Â™ re raging through the houses and comm\n",
      "re sitting here right now . They donÃ¢ Â€Â™ t have a home any longer . ThatÃ¢ Â€Â™ s\n",
      "Ã¢ Â€Â™ t have a home any longer . ThatÃ¢ Â€Â™ s interesting . But we canÃ¢ Â€Â™ t let \n",
      " ThatÃ¢ Â€Â™ s interesting . But we canÃ¢ Â€Â™ t let this happen . Everyone is unabl\n",
      "nable to do anything about it . ThatÃ¢ Â€Â™ s going to change . We have a public \n",
      "edom . From this moment on , AmericaÃ¢ Â€Â™ s decline is over . Our liberties and\n",
      " over . Our liberties and our nationÃ¢ Â€Â™ s glorious destiny will no longer be \n",
      " competency , and loyalty of AmericaÃ¢ Â€Â™ s government . Over the past eight ye\n",
      "nt in our 250 - year history , and IÃ¢ Â€Â™ ve learned a lot along the way . The \n",
      "ful Pennsylvania field , an assassinÃ¢ Â€Â™ s bullet ripped through my ear . But \n",
      "cords , and I will not forget it . IÃ¢ Â€Â™ ve heard your voices in the campaign \n",
      "and we will not forget our God . CanÃ¢ Â€Â™ t do that . Today , I will sign a ser\n",
      " the revolution of common sense . ItÃ¢ Â€Â™ s all about common sense . First , I \n",
      "Ã¢ Â€Â” and we are going to use it . WeÃ¢ Â€Â™ ll use it . We will bring prices down\n",
      "n autoworkers . In other words , youÃ¢ Â€Â™ ll be able to buy the car of your cho\n",
      "ocial experiments while on duty . ItÃ¢ Â€Â™ s going to end immediately . Our arme\n",
      "eir sole mission : defeating AmericaÃ¢ Â€Â™ s enemies . Like in 2017 , we will ag\n",
      "t of a peacemaker and unifier . ThatÃ¢ Â€Â™ s what I want to be : a peacemaker an\n",
      " be : a peacemaker and a unifier . IÃ¢ Â€Â™ m pleased to say that as of yesterday\n",
      "ld have never been made , and PanamaÃ¢ Â€Â™ s promise to us has been broken . The\n",
      "ating the Panama Canal . And we didnÃ¢ Â€Â™ t give it to China . We gave it to Pa\n",
      "hina . We gave it to Panama , and weÃ¢ Â€Â™ re taking it back . Above all , my me\n",
      " vigor , and the vitality of historyÃ¢ Â€Â™ s greatest civilization . So , as we \n",
      "ore ambitious than any other . ThereÃ¢ Â€Â™ s no nation like our nation . America\n",
      "or you , and I will win for you . WeÃ¢ Â€Â™ re going to win like never before . T\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "\n",
    "Text(inaugural.words(\"2025-Trump.txt\")).concordance(\"\\x80\\x99\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2832a3-1a56-4eb3-b5a4-7c4c45c7164a",
   "metadata": {},
   "source": [
    "What do you think `'\\x80\\x99'` means? Why is it in the corpus, and why is it always preceded by a word ending in `Ã¢`?\n",
    "\n",
    "**Hint:** Let's check what encoding is used in the Inaugural Addresses corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3086665-1973-49ed-9bc0-45e34c227bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latin1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.encoding(\"2025-Trump.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc237ac-a8d3-4942-82b5-85065aad4657",
   "metadata": {},
   "source": [
    "Now, try looking up how `Ã¢` is represented in this encoding (you may need to convert it from hexadecimal to binary representation), and revisit Problem 1a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb8aa6-d566-497a-bbdf-e82a8a22f294",
   "metadata": {},
   "source": [
    "### Problem 2c: Fix Encoding Issues (Code, 1 Point)\n",
    "\n",
    "Problem 2b shows that the Inaugural Addresses corpus contains [_mojibake_](https://en.wikipedia.org/wiki/Mojibake)â€”weird text that results from files being read using the wrong encoding. In this problem, you will remove all mojibake from the Inaugural Addresses corpus by setting each file in the corpus to its correct encoding.\n",
    "\n",
    "NLTK corpora are represented by the [`CorpusReader` class](https://www.nltk.org/api/nltk.corpus.reader.api.html#nltk.corpus.reader.api.CorpusReader). `CorpusReader`s contain a property called `._encoding`, which contains the encoding used for the corpus. Let's check the value of this property for the Inaugural Addresses corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db250e05-9d07-46f9-9edc-92e530883534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latin1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural._encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e425a83-49ae-4194-86d1-42e5c794436f",
   "metadata": {},
   "source": [
    "Notice that the name of the `CorpusReader._encoding` property begins with an underscore (`_`). When a property begins with an underscore, it usually means that that property is for \"internal use\"; the authors of the class don't want you to use or change the value of that property from outside the class definition. But this is merely a suggestion, not a requirement. So let's try to fix the Inaugural Addresses corpus by changing its encoding to UTF-8, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affd07b8-5019-41db-90de-a5538efc7656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-Bush.txt is incompatible with UTF-8!\n"
     ]
    }
   ],
   "source": [
    "# Try setting the encoding to UTF-8\n",
    "inaugural._encoding = \"utf8\"\n",
    "\n",
    "# Will this mess up any of the files in the corpus?\n",
    "msg = \"No encoding errors detected!\"\n",
    "for f in inaugural.fileids():\n",
    "    try:\n",
    "        _ = list(inaugural.words(f))\n",
    "    except UnicodeDecodeError:\n",
    "        msg = f\"{f} is incompatible with UTF-8!\"\n",
    "        break\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db500e-0d26-4768-ad99-de34eb52f679",
   "metadata": {},
   "source": [
    "It seems, based on the code above, that not all files in the corpus are compatible with the UTF-8 encoding. Therefore, we will need to individually specify the encoding of each file, using a dict of the form:\n",
    "\n",
    "```python\n",
    "inaugural._encoding = {\"1789-Washington.txt\": \"latin1\",\n",
    "                       \"1793-Washington.txt\": \"latin1\",\n",
    "                       ...,\n",
    "                       \"2025-Trump.txt\": \"utf8\"}\n",
    "```\n",
    "\n",
    "Please implement the function `hw2.get_encodings`, which takes an NLTK corpus and returns the encoding for each file in the corpus, in the form of a `dict`. Please assume that a file's corpus should be `'utf8'` if it contains at least one token ending in `Ã¢` when loaded in `latin1` encoding, and that it should be `latin1` otherwise. When implemented correctly, the output of your function should be as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e4c4040-f1f3-44d4-a1de-898613e6949e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1789-Washington.txt': 'latin1',\n",
       " '1793-Washington.txt': 'latin1',\n",
       " '1797-Adams.txt': 'latin1',\n",
       " '1801-Jefferson.txt': 'latin1',\n",
       " '1805-Jefferson.txt': 'latin1',\n",
       " '1809-Madison.txt': 'latin1',\n",
       " '1813-Madison.txt': 'latin1',\n",
       " '1817-Monroe.txt': 'latin1',\n",
       " '1821-Monroe.txt': 'latin1',\n",
       " '1825-Adams.txt': 'latin1',\n",
       " '1829-Jackson.txt': 'latin1',\n",
       " '1833-Jackson.txt': 'latin1',\n",
       " '1837-VanBuren.txt': 'latin1',\n",
       " '1841-Harrison.txt': 'latin1',\n",
       " '1845-Polk.txt': 'latin1',\n",
       " '1849-Taylor.txt': 'latin1',\n",
       " '1853-Pierce.txt': 'latin1',\n",
       " '1857-Buchanan.txt': 'latin1',\n",
       " '1861-Lincoln.txt': 'latin1',\n",
       " '1865-Lincoln.txt': 'latin1',\n",
       " '1869-Grant.txt': 'latin1',\n",
       " '1873-Grant.txt': 'latin1',\n",
       " '1877-Hayes.txt': 'latin1',\n",
       " '1881-Garfield.txt': 'latin1',\n",
       " '1885-Cleveland.txt': 'latin1',\n",
       " '1889-Harrison.txt': 'latin1',\n",
       " '1893-Cleveland.txt': 'latin1',\n",
       " '1897-McKinley.txt': 'latin1',\n",
       " '1901-McKinley.txt': 'latin1',\n",
       " '1905-Roosevelt.txt': 'latin1',\n",
       " '1909-Taft.txt': 'latin1',\n",
       " '1913-Wilson.txt': 'latin1',\n",
       " '1917-Wilson.txt': 'latin1',\n",
       " '1921-Harding.txt': 'latin1',\n",
       " '1925-Coolidge.txt': 'latin1',\n",
       " '1929-Hoover.txt': 'latin1',\n",
       " '1933-Roosevelt.txt': 'latin1',\n",
       " '1937-Roosevelt.txt': 'latin1',\n",
       " '1941-Roosevelt.txt': 'latin1',\n",
       " '1945-Roosevelt.txt': 'latin1',\n",
       " '1949-Truman.txt': 'latin1',\n",
       " '1953-Eisenhower.txt': 'latin1',\n",
       " '1957-Eisenhower.txt': 'latin1',\n",
       " '1961-Kennedy.txt': 'latin1',\n",
       " '1965-Johnson.txt': 'latin1',\n",
       " '1969-Nixon.txt': 'latin1',\n",
       " '1973-Nixon.txt': 'latin1',\n",
       " '1977-Carter.txt': 'latin1',\n",
       " '1981-Reagan.txt': 'latin1',\n",
       " '1985-Reagan.txt': 'latin1',\n",
       " '1989-Bush.txt': 'latin1',\n",
       " '1993-Clinton.txt': 'latin1',\n",
       " '1997-Clinton.txt': 'latin1',\n",
       " '2001-Bush.txt': 'latin1',\n",
       " '2005-Bush.txt': 'latin1',\n",
       " '2009-Obama.txt': 'latin1',\n",
       " '2013-Obama.txt': 'utf8',\n",
       " '2017-Trump.txt': 'utf8',\n",
       " '2021-Biden.txt': 'utf8',\n",
       " '2025-Trump.txt': 'utf8'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural._encoding = \"latin1\"\n",
    "hw2.get_encodings(inaugural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c7fc2-51db-42d6-95a7-be8b8dd38f98",
   "metadata": {},
   "source": [
    "Now, let's use your code to set all files in the corpus to the correct encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edcc1e46-6a03-4622-ae0d-130013e467c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No encoding errors detected!\n",
      "Looking up '\\x80\\x99'...\n",
      "no matches\n"
     ]
    }
   ],
   "source": [
    "# Set all the files to the correct encoding\n",
    "inaugural._encoding = hw2.get_encodings(inaugural)\n",
    "\n",
    "# Will this mess up any of the files in the corpus?\n",
    "msg = \"No encoding errors detected!\"\n",
    "for f in inaugural.fileids():\n",
    "    try:\n",
    "        _ = list(inaugural.words(f))\n",
    "    except UnicodeDecodeError:\n",
    "        msg = f\"{f} is incompatible with UTF-8!\"\n",
    "        break\n",
    "print(msg)\n",
    "\n",
    "# Do we still get mojibake?\n",
    "print(\"Looking up '\\\\x80\\\\x99'...\") \n",
    "Text(inaugural.words()).concordance(\"\\x80\\x99\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c119167-3da0-4d23-b72e-305e9bb33266",
   "metadata": {},
   "source": [
    "### Problem 2d: Compare Inaugural Address Keywords (Written, 1 Point)\n",
    "\n",
    "Using the entire Inaugural Addresses corpus as a reference, and using a smoothing constant of $k = 1$, look at the top 100 keywords of Donald Trump's 2025 inaugural address and Joe Biden's 2021 inaugural address. What are some interesting differences between the keywords for these two addresses?\n",
    "\n",
    "In your submission, you do not need to write down all 200 keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98105412-cbcf-4fd3-a67a-200330a8809f",
   "metadata": {},
   "source": [
    "### Problem 2e: Understand Feature Tagging (Written, 1 Point)\n",
    "\n",
    "[Egbert and Biber (2023)](https://www.euppublishing.com/doi/10.3366/cor.2023.0275) propose a corpus analysis method called _key feature analysis_. In keyword analysis, we are looking for token types that characterize one corpus relative to another. In key feature analysis, we are looking for higher-level grammatical features that characterize one corpus relative to another.\n",
    "\n",
    "To help us perform key feature analysis, we will use the [Biberplus feature tagger](https://github.com/davidjurgens/biberplus) by [Alkiek et al. (2025, Subsection 3.1)](https://arxiv.org/abs/2502.18590v1), a piece of Python code that will annotate each token in a string with its grammatical features. Let's load the Biberplus packageâ€¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "029e88fd-0e1e-44e7-a162-c0ae28c00590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biberplus.tagger import tag_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30ac12-86d8-4540-a656-c5d5e1dc1ffb",
   "metadata": {},
   "source": [
    "â€¦and let's try tagging some text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "728de9de-173f-4a4e-966e-4c2dd0a4f126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Alice',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': Number=Sing,\n",
       "  'tags': ['CAP', 'NNP']},\n",
       " {'text': 'saw',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBD',\n",
       "  'feats': Tense=Past|VerbForm=Fin,\n",
       "  'tags': ['VBD', 'PRIV']},\n",
       " {'text': 'Bob',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': Number=Sing,\n",
       "  'tags': ['CAP', 'NNP']},\n",
       " {'text': 'in',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'feats': '',\n",
       "  'tags': ['in', 'PIN', 'CONJ', 'PREP']},\n",
       " {'text': 'the',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DT',\n",
       "  'feats': Definite=Def|PronType=Art,\n",
       "  'tags': ['the', 'ART', 'DET']},\n",
       " {'text': 'park',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': Number=Sing,\n",
       "  'tags': ['NN']},\n",
       " {'text': '.',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': '.',\n",
       "  'feats': PunctType=Peri,\n",
       "  'tags': []}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_text(\"Alice saw Bob in the park.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5638b-c880-4e25-bb1c-550a4ce8ec2e",
   "metadata": {},
   "source": [
    "The output of `tag_text` is a `list[dict[str, Any]]`, where each `dict` contains morphosyntactic information about a particular token in the sentence. The features we care about are the ones associated with the `tags` key in each of the `dicts`. A description of these tags is given in Appendix A of [Alkiek et al. (2025)](https://arxiv.org/abs/2502.18590v1).\n",
    "\n",
    "In the output above, the token `'Alice'` is associated with the tags `['CAP', 'NNP']`, while the token `'saw'` is associated with the tags `['VBD', 'PRIV']`. What do each of these tags mean (`'CAP'`, `'NNP'`, `'VBD'`, and `'PRIV'`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f788672-b755-45f0-944c-ef961d5f0384",
   "metadata": {},
   "source": [
    "### Problem 2f: Implement Feature Tagging (Code, 1 Point)\n",
    "\n",
    "Please implement the function `hw2.feature_dist`, which takes an untokenized text and returns the counts of each possible feature tag as a `FreqDist`. For example, the feature tag `'CAP'` occurs twice in the above output, once with `'Alice'` and once with `'Bob'`; as shown below, the count of this tag within the sentence `'Alice saw Bob in the park.'` is therefore 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d17620f5-7ebb-453e-bc11-1d0aeea73bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'CAP': 2, 'NNP': 2, 'VBD': 1, 'PRIV': 1, 'in': 1, 'PIN': 1, 'CONJ': 1, 'PREP': 1, 'the': 1, 'ART': 1, ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = hw2.feature_dist(\"Alice saw Bob in the park.\")\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b3b3c22-292a-4383-b933-fac983670d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAP occurs 2 time(s).\n",
      "NNP occurs 2 time(s).\n",
      "VBD occurs 1 time(s).\n",
      "PRIV occurs 1 time(s).\n",
      "in occurs 1 time(s).\n",
      "PIN occurs 1 time(s).\n",
      "CONJ occurs 1 time(s).\n",
      "PREP occurs 1 time(s).\n",
      "the occurs 1 time(s).\n",
      "ART occurs 1 time(s).\n",
      "DET occurs 1 time(s).\n",
      "NN occurs 1 time(s).\n"
     ]
    }
   ],
   "source": [
    "# Visualize the entire FreqDist\n",
    "for tag, count in fd.items():\n",
    "    print(f\"{tag} occurs {count} time(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6948aaa-6f36-4cca-bf69-cbc5ba345656",
   "metadata": {},
   "source": [
    "### Problem 2g: Find Key Features of Inaugural Addresses (Written, 1 Point)\n",
    "\n",
    "Once feature tagging has been implemented, we can use it to analyze the key features of inaugural addresses. For example, here are the top 5 key features of Donald Trump's 2025 inaugural address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bbf5261-1215-4d6b-9593-ee8d3c7081d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nobody', 32.93226707286113),\n",
       " ('everybody', 24.949200304645846),\n",
       " ('SPIN', 12.307933485656257),\n",
       " ('something', 6.7790897392126475),\n",
       " ('UH', 6.294666744780987)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_features = hw2.feature_dist(inaugural.raw(\"2025-Trump.txt\"))\n",
    "ref_features = hw2.feature_dist(inaugural.raw())\n",
    "hw1.freq_ratio(trump_features, ref_features).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b613053-f770-4453-a0c6-b7dd514f334f",
   "metadata": {},
   "source": [
    "Take a look at the top 25 key features of Donald Trump's 2025 inaugural address and Joe Biden's 2021 inaugural address. Use the entire Inaugural Addresses corpus as a reference, and use a smoothing constant of $k = 1$. Do you notice any interesting patterns?\n",
    "\n",
    "You do not need to write down all 50 key features in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87448d9-734f-4752-8c90-f21fe5067875",
   "metadata": {},
   "source": [
    "## Problem 3: Analysis of Nomination Acceptance Speeches (8 Points in Total)\n",
    "\n",
    "Now, you will apply keyword analysis and key feature analysis to nomination acceptance speeches given by US presidential candidates at the Democratic and Republican National Conventions. Unfortunately, NLTK does not provide these speeches as a corpus. Instead, you will use texts from [UC Santa Barbara's American Presidency Project](https://www.presidency.ucsb.edu/documents/app-categories/elections-and-transitions/convention-speeches/presidential-nomination-0), which have been downloaded for you and provided with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac99f2b-8a9e-452d-9061-ef14868d2e56",
   "metadata": {},
   "source": [
    "### Problem 3a: Extract Text From Speeches (Code, 1 Point)\n",
    "\n",
    "The `convention_speeches` folder contains the HTML file for each nomination acceptance speech available at the American Presidency Project. For example, the file [2024-Harris-DNC.html](convention_speeches/2024-Harris-DNC.html) in this folder was downloaded from the following URL: [https://www.presidency.ucsb.edu/documents/address-accepting-the-democratic-presidential-nomination-chicago-illinois](https://www.presidency.ucsb.edu/documents/address-accepting-the-democratic-presidential-nomination-chicago-illinois)\n",
    "\n",
    "Please implement the function `hw2.get_raw_text_from_html`, which extracts the text of a nomination acceptance speech from its corresponding HTML file. The content of each `p` element in the HTML file (i.e., the text appearing between the tags `<p>...</p>`) should be joined with `'\\n'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "884db84ee5d3988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Vice President: Good evening! [Laughs.] [Applause.]\\nAudience: Kamala! Kamala! Kamala!\\nThe Vice President: California. [Laughs.] [Applause.]\\nGood evening, everyone. Good evening. [Laughs.] [Applause.] Good evening. [Laughs.] [Applause.]\\nOh, my goodness. [Applause.]\\nGood evening, everyone. Good evening. Go- â€” [laughs]. [Applause.] Good evening. Thank you. [Applause.]\\nThank you. Thank you. [Applause.]\\nAudience: Kamala! Kamala! Kamala!\\nThe Vice President: Good evening. [Applause.]\\nThank you. Thank you. Thank â€” thank you. [Applause.] Thank you. Thank you, everyone. Thank you. [Applause.] Thank you. Thank you. [Applause.]\\nAudience: USA! USA! USA!\\nThe Vice President: Thank you all.\\nAudience: USA! USA! USA!\\nThe Vice President: Thank you all. [Applause.]\\nOkay, we've got to get to some business. We've got to get to some business.\\nOkay. Thank you all. [Applause.] Okay. [Laughs.] Thank you, thank you, thank you, thank you, thank you. [Applause.] Thank you, thank you. Please. Thank you. [Applau\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw2.get_raw_text_from_html(\"convention_speeches/2024-Harris-DNC.html\")[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c01ae-a2c6-4f78-88b4-17b4e0c882b6",
   "metadata": {},
   "source": [
    "### Problem 3b: Understand Preprocessing (No Submission, 0 Points)\n",
    "\n",
    "Notice that the text for Kamala Harris's 2024 nomination acceptance speech contains non-linguistic elements like `'[Laughs.]'` and `'[Applause.]'`. The function `hw2.preprocess` removes these elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "106bb198-ff30-410b-8eea-c038ceb781a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Vice President: Good evening! \\nAudience: Kamala! Kamala! Kamala!\\nThe Vice President: California. \\nGood evening, everyone. Good evening. \\nOh, my goodness. \\nGood evening, everyone. Good evening. Go- â€” \\nThank you. Thank you. \\nAudience: Kamala! Kamala! Kamala!\\nThe Vice President: Good evening. \\nThank you. Thank you. Thank â€” thank you. \\nAudience: USA! USA! USA!\\nThe Vice President: Thank you all.\\nAudience: USA! USA! USA!\\nThe Vice President: Thank you all. \\nOkay, we've got to get to some business. We've got to get to some business.\\nOkay. Thank you all. \\nPlease. Thank you so very much. Thank you, everyone. Thank you, everyone. Thank you. \\nOkay, let's get to business. Let's get to business. All right. \\nSo, let me start by thanking my most incredible husband, Doug â€”  I love you so very much.\\nTo our president, Joe Biden â€” \\nAnd to Coach Tim Walz â€” \\nAnd to the delegates and everyone who has put your faith in our campaign, your support is humbling.\\nSo, America, the path that led me here in recen\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw2.preprocess(hw2.get_raw_text_from_html(\"convention_speeches/2024-Harris-DNC.html\"))[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf1d40-cba8-4caa-83d5-18eb2ab6dc5b",
   "metadata": {},
   "source": [
    "### Problem 3c: Implement ConventionSpeechCorpus Constructor (Code, 1 Point)\n",
    "\n",
    "You will organize the nomination acceptance speeches by loading them into a `ConventionSpeechCorpus` object. The `ConventionSpeechCorpus` class, defined in `hw2`, behaves similarly to an NLTK corpus: it has methods like `.fileid`, `.raw`, and `.words`, whose NLTK counterparts you used extensively in Problem 2.\n",
    "\n",
    "Please inspect the constructor (`.__init__` method) of `ConventionSpeechCorpus`, and complete its implementation. As shown below, `ConventionSpeechCorpus` objects can be constructed from the name of a single HTML file, or from the name of a folder containing a collection of HTML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "116d148f-5787-40d3-93fd-aeef64083f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convention_speeches/2024-Harris-DNC.html']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a ConventionSpeechCorpus for a single HTML file\n",
    "harris_corpus = hw2.ConventionSpeechCorpus(\"convention_speeches/2024-Harris-DNC.html\")\n",
    "harris_corpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b34b9a14-bdc0-4dff-9020-103b3c598c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convention_speeches/1932-Roosevelt-DNC.html',\n",
       " 'convention_speeches/1936-Roosevelt-DNC.html',\n",
       " 'convention_speeches/1940-Roosevelt-DNC.html',\n",
       " 'convention_speeches/1944-Dewey-RNC.html',\n",
       " 'convention_speeches/1944-Roosevelt-DNC.html',\n",
       " 'convention_speeches/1948-Dewey-RNC.html',\n",
       " 'convention_speeches/1948-Truman-DNC.html',\n",
       " 'convention_speeches/1952-Eisenhower-RNC.html',\n",
       " 'convention_speeches/1952-Stevenson-DNC.html',\n",
       " 'convention_speeches/1956-Eisenhower-RNC.html',\n",
       " 'convention_speeches/1956-Stevenson-DNC.html',\n",
       " 'convention_speeches/1960-Kennedy-DNC.html',\n",
       " 'convention_speeches/1960-Nixon-RNC.html',\n",
       " 'convention_speeches/1964-Goldwater-RNC.html',\n",
       " 'convention_speeches/1964-Johnson-DNC.html',\n",
       " 'convention_speeches/1968-Humphrey-DNC.html',\n",
       " 'convention_speeches/1968-Nixon-RNC.html',\n",
       " 'convention_speeches/1972-McGovern-DNC.html',\n",
       " 'convention_speeches/1972-Nixon-RNC.html',\n",
       " 'convention_speeches/1976-Carter-DNC.html',\n",
       " 'convention_speeches/1976-Ford-RNC.html',\n",
       " 'convention_speeches/1976-Reagan-RNC.html',\n",
       " 'convention_speeches/1980-Carter-DNC.html',\n",
       " 'convention_speeches/1984-Mondale-DNC.html',\n",
       " 'convention_speeches/1984-Reagan-RNC.html',\n",
       " 'convention_speeches/1988-Bush-RNC.html',\n",
       " 'convention_speeches/1988-Dukakis-DNC.html',\n",
       " 'convention_speeches/1992-Bush-RNC.html',\n",
       " 'convention_speeches/1992-Clinton-DNC.html',\n",
       " 'convention_speeches/1996-Clinton-DNC.html',\n",
       " 'convention_speeches/1996-Dole-RNC.html',\n",
       " 'convention_speeches/2000-Bush-RNC.html',\n",
       " 'convention_speeches/2000-Gore-DNC.html',\n",
       " 'convention_speeches/2004-Bush-RNC.html',\n",
       " 'convention_speeches/2004-Kerry-DNC.html',\n",
       " 'convention_speeches/2008-McCain-RNC.html',\n",
       " 'convention_speeches/2008-Obama-DNC.html',\n",
       " 'convention_speeches/2012-Obama-DNC.html',\n",
       " 'convention_speeches/2012-Romney-RNC.html',\n",
       " 'convention_speeches/2016-Clinton-DNC.html',\n",
       " 'convention_speeches/2016-Trump-RNC.html',\n",
       " 'convention_speeches/2020-Biden-DNC.html',\n",
       " 'convention_speeches/2020-Trump-RNC.html',\n",
       " 'convention_speeches/2024-Harris-DNC.html',\n",
       " 'convention_speeches/2024-Trump-RNC.html']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a ConventionSpeechCorpus for a folder of HTML files\n",
    "nomination_acceptance = hw2.ConventionSpeechCorpus(\"convention_speeches\")\n",
    "nomination_acceptance.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5527d-a23d-4fe1-a18b-0889961aedd0",
   "metadata": {},
   "source": [
    "Currently, the `ConventionSpeechCorpus` constructor only supports constructing a `ConventionSpeechCorpus` object from a single HTML file. You are responsible for adding support for constructing a `ConventionSpeechCorpus` object from a folder of HTML files.\n",
    "\n",
    "**Notes:**\n",
    "- If the folder contains things other than HTML files (i.e., sub-directories or files not ending in `.html`), those things should not be included in the `ConventionSpeechCorpus` object.\n",
    "- If the folder does not contain any HTML files, then the constructed `ConventionSpeechCorpus` object should be blank.\n",
    "\n",
    "**Hint:** Please use [the `os.listdir` function](https://www.w3schools.com/python/ref_os_listdir.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b970fdb-52dc-48f0-bacc-f9d6d66096a2",
   "metadata": {},
   "source": [
    "### Problem 3d: Implement ConventionSpeechCorpus Methods (Code, 2 Points)\n",
    "\n",
    "Please implement the `.raw` and `.words` methods of `ConventionSpeechCorpus`. These methods should behave similarly to their counterparts in NLTK corpora, like `inaugural.raw` and `inaugural.words`.\n",
    "\n",
    "The `.raw` method should return the raw text for one or more files in a `ConventionSpeechCorpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "374d14ac-5e2b-4135-86c9-7cc26b76cd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Vice President: Good evening! \\nAudience: Kamala! Kamala! Kamala!\\nThe Vice President: California. \\nGood evening, everyone. Good evening. \\nOh, my goodness. \\nGood evening, everyone. Good evening. Go- â€” \\nThank you. Thank you. \\nAudience: Kamala! Kamala! Kamala!\\nThe Vice President: Good evening. \\nThank you. Thank you. Thank â€” thank you. \\nAudience: USA! USA! USA!\\nThe Vice President: Thank you all.\\nAudience: USA! USA! USA!\\nThe Vice President: Thank you all. \\nOkay, we've got to get to some business. We've got to get to some business.\\nOkay. Thank you all. \\nPlease. Thank you so very much. Thank you, everyone. Thank you, everyone. Thank you. \\nOkay, let's get to business. Let's get to business. All right. \\nSo, let me start by thanking my most incredible husband, Doug â€”  I love you so very much.\\nTo our president, Joe Biden â€” \\nAnd to Coach Tim Walz â€” \\nAnd to the delegates and everyone who has put your faith in our campaign, your support is humbling.\\nSo, America, the path that led me here in recen\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomination_acceptance.raw(\"convention_speeches/2024-Harris-DNC.html\")[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c02631-cdaf-4abf-b090-53cb78ceaf9a",
   "metadata": {},
   "source": [
    "The `.words` method should return tokenized text for one or more files in a `ConventionSpeechCorpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bfb5d0e-e2b8-4d94-afd4-7a7399cf33de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Vice',\n",
       " 'President',\n",
       " ':',\n",
       " 'Good',\n",
       " 'evening',\n",
       " '!',\n",
       " 'Audience',\n",
       " ':',\n",
       " 'Kamala']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomination_acceptance.words(\"convention_speeches/2024-Harris-DNC.html\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660735a8-e5e1-497c-813b-478ee9dc7394",
   "metadata": {},
   "source": [
    "Both methods should support loading multiple files, or all files in a `ConventionSpeechCorpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe221656-e6f7-4c9c-b661-4d3d7ad340f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two files\n",
    "_ = nomination_acceptance.raw([\"convention_speeches/2024-Harris-DNC.html\",\n",
    "                               \"convention_speeches/2024-Trump-RNC.html\"])\n",
    "_ = nomination_acceptance.words([\"convention_speeches/2024-Harris-DNC.html\",\n",
    "                                \"convention_speeches/2024-Trump-RNC.html\"])\n",
    "\n",
    "# Load all files\n",
    "_ = nomination_acceptance.raw()\n",
    "_ = nomination_acceptance.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e9f5b0-0d50-43a4-af5b-dc19c1838d4a",
   "metadata": {},
   "source": [
    "If you try loading a file that doesn't exist within the `ConventionSpeechCorpus`, you should get a `ValueError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dd9e9cb-d3a0-4183-8baf-d5a6166438b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There is no file called fake_file.html in this corpus!",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Load a non-existent file\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mnomination_acceptance\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraw\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfake_file.html\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m[path redacted]/hw2.py:[line number redacted]\u001B[39m, in \u001B[36mConventionSpeechCorpus.raw\u001B[39m\u001B[34m(self, files)\u001B[39m\n\u001B[32m       \u001B[39m [code redacted]\n",
      "\u001B[31mValueError\u001B[39m: There is no file called fake_file.html in this corpus!"
     ]
    }
   ],
   "source": [
    "# Load a non-existent file\n",
    "nomination_acceptance.raw(\"fake_file.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bd84087-c655-46e3-9270-5248d58c5804",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There is no file called fake_file.html in this corpus!",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Load multiple files, including a non-existent file\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mnomination_acceptance\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mconvention_speeches/2024-Harris-DNC.html\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m                             \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfake_file.html\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m                             \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mconvention_speeches/2024-Trump-RNC.html\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m[path redacted]/hw2.py:[line number redacted]\u001B[39m, in \u001B[36mConventionSpeechCorpus.words\u001B[39m\u001B[34m(self, files)\u001B[39m\n\u001B[32m       \u001B[39m [code redacted]\n",
      "\u001B[31mValueError\u001B[39m: There is no file called fake_file.html in this corpus!"
     ]
    }
   ],
   "source": [
    "# Load multiple files, including a non-existent file\n",
    "nomination_acceptance.words([\"convention_speeches/2024-Harris-DNC.html\",\n",
    "                             \"fake_file.html\",\n",
    "                             \"convention_speeches/2024-Trump-RNC.html\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5013b2c9-e4bb-41b7-8a98-0832c0d5da5d",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- Please read the docstrings for these methods very carefully!\n",
    "- For grading purposes, it doesn't matter what error message you put into the `ValueError`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493461c-4353-4f83-9498-74046b2e103e",
   "metadata": {},
   "source": [
    "### Problem 3e: Nomination Acceptance Speeches vs. Inaugural Addresses (Written, 1 Point)\n",
    "\n",
    "What are the top five keywords and key features of:\n",
    "- the nomination acceptance speeches, all concatenated into a single corpus?\n",
    "- the inaugural addresses, all concatenated into a single corpus?\n",
    "\n",
    "Please use a smoothing constant of $k = 1$. For your reference corpus, please use the concatenation of the nomination acceptance speeches and the inaugural addresses corpus.\n",
    "\n",
    "**Hint:** Remember that you can add `FreqDist`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb33ebe-7be0-48cf-9551-ad6b2300f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code to help you solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ebaf34-016c-4b13-a028-8a21d27f797a",
   "metadata": {},
   "source": [
    "### Problem 3f: Democratic Speeches vs. Republican Speeches (Written, 1 Point)\n",
    "\n",
    "What are the top five keywords and key features of:\n",
    "- the nomination acceptance speeches given at the Democratic National Convention (DNC), all concatenated into a single corpus?\n",
    "- the nomination acceptance speeches given at the Republican National Convention (RNC), all concatenated into a single corpus?\n",
    "\n",
    "Please use a smoothing constant of $k = 1$. For your reference corpus, please use the concatenation of the all nomination acceptance speeches, regardless of parties.\n",
    "\n",
    "**Hints:** \n",
    "- Remember that you can add `FreqDist`s.\n",
    "- Look at the filename for each speech.\n",
    "- What is the value of the Python expression `'bc' in 'abcde'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c7613-30ff-426e-8737-5c1a517e7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code to help you solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a46d1-8e1d-4e65-8890-f2f394c41107",
   "metadata": {},
   "source": [
    "### Problem 3g: Deep Dive (Written, 2 Points)\n",
    "\n",
    "Using keyword analysis and/or key feature analysis, what can you say about the differences between:\n",
    "- inaugural addresses and nomination acceptance speeches, and\n",
    "- Democratic vs. Republican nomination acceptance speeches?\n",
    "\n",
    "Please base your answers on at least 25 key words and/or key features from both sets of speeches in each comparison. That is, you should look at at least 25 key words and/or key features from the inaugural addresses, nomination acceptance speeches, DNC speeches, and RNC speeches, each with an appropriate reference corpus. You do not need to write down all 25 key words and/or key features for each corpus in your answer; just describe any interesting observations you make from this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79217c-721c-484b-8532-4bb7c5fc36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to write code to help you solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ba8b8-4d51-47a8-a395-fb65886c188b",
   "metadata": {},
   "source": [
    "## Problem 4: Optional Further Reading (No Submission, 0 Points)\n",
    "\n",
    "Egbert and Biber (2020) conduct a detailed key feature analysis of Donald Trump's presidential debates. This paper is available on Blackboard under Assignments; please read it at your own leisure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
